{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import torch as nn\n",
    "import numpy as np\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('dataset/dataframe_restaurant_10_50.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create <anchor, postive , negative> dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "\n",
    "def create_triplets(df, anchors_per_item,enforce_max_length=True, max_length=10000):\n",
    "    if enforce_max_length:\n",
    "        max_length = max_length\n",
    "    else:\n",
    "        max_length = np.inf\n",
    "        \n",
    "    triplets_list =[]\n",
    "    while len(triplets_list) < max_length:\n",
    "        user = np.random.choice(df['User_id'].unique(),replace=False)\n",
    "        user_df = df[df['User_id'] == user]\n",
    "        _, indices = np.unique(user_df['Business_id'], return_index=True)\n",
    "        length= len(indices)\n",
    "        if length< anchors_per_item:\n",
    "            continue\n",
    "        else:\n",
    "            selected_indices = np.random.choice(indices, size=anchors_per_item, \n",
    "                                                    replace=False)\n",
    "            \n",
    "            ratings = user_df['Rating'].iloc[selected_indices]\n",
    "            anchor_indexes = ratings.index.values\n",
    "            flag=False\n",
    "            for rating, index, anchor_index in zip(ratings,selected_indices,anchor_indexes):\n",
    "\n",
    "                \"\"\" Assuming the rating is only 4 and 5, we use a simple\n",
    "                 is equals and not equals to get the positive and negative \"\"\"\n",
    "                if flag:\n",
    "                    break\n",
    "\n",
    "                positive_indices = ratings.index[(ratings == rating) & \n",
    "                                                 (ratings.index != anchor_index)]\n",
    "\n",
    "                negative_indices = ratings.index[ratings != rating]\n",
    "                flag = True\n",
    "                for i in range(min(len(positive_indices),len(negative_indices))):\n",
    "                    \n",
    "                    #user_id = user_df['User_id'].iloc[index]\n",
    "                    #pos_id  = user_df['User_id'].loc[positive_indices[i]]\n",
    "                    triplets_list.append([anchor_index,positive_indices[i],\n",
    "                                         negative_indices[i],])\n",
    "                    \n",
    "                    \n",
    "                    flag = False\n",
    "\n",
    "    triplets_df = pd.DataFrame(triplets_list,columns=['anchor','positive','negative'])\n",
    "    return triplets_df\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets= create_triplets(df, 10, max_length=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Contrastive Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Contrastive structure can be obtainined from the triplet structure \"\"\"\n",
    "contrastive_df = triplets[['positive', 'negative']].copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating custom dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, triplets_df, df):\n",
    "        self.triplets_df = triplets_df\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.triplets_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" Retrun the \"User_id\", \"Business_id\" and \"Rating\" of df.iloc[idx], where\n",
    "         idx is the value stores in the \"anchor\", \"positive\" and \"negative\" columns.\n",
    "        \n",
    "         Final output should be 3 user-item-rating tuples \"\"\"\n",
    "        anchor_idx = self.triplets_df['anchor'].iloc[idx]\n",
    "        positive_idx = self.triplets_df['positive'].iloc[idx]\n",
    "        negative_idx = self.triplets_df['negative'].iloc[idx]\n",
    "\n",
    "        anchor_val = self.df.loc[anchor_idx].to_list()\n",
    "        positive_val = self.df.loc[positive_idx].to_list()\n",
    "        negative_val = self.df.loc[negative_idx].to_list()\n",
    "\n",
    "        return anchor_val, positive_val, negative_val\n",
    "    \n",
    "triplet_dataset = TripletDataset(triplets, df[['User_id', 'Business_id', 'Rating']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Convert the list of tuples into separate lists for each component (User_id, Business_id, Rating)\n",
    "    anchor_vals, positive_vals, negative_vals = zip(*batch)\n",
    "\n",
    "    # Stack the lists to create tensors for each component\n",
    "    anchor_tensor = torch.tensor(anchor_vals)\n",
    "    positive_tensor = torch.tensor(positive_vals)\n",
    "    negative_tensor = torch.tensor(negative_vals)\n",
    "\n",
    "    # Stack the tensors along dimension 1 to create a single tensor of shape (batch_size, 3)\n",
    "    combined_tensor = torch.stack((anchor_tensor, positive_tensor, negative_tensor), dim=1)\n",
    "\n",
    "    return combined_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_dataloader = DataLoader(triplet_dataset, batch_size=10,collate_fn=collate_fn, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 1 batch\n",
    "anchor = next(iter(triplet_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0514e+06, 1.3393e+04, 5.0000e+00],\n",
       "        [1.0514e+06, 1.8300e+04, 5.0000e+00],\n",
       "        [1.0514e+06, 4.1222e+04, 5.0000e+00],\n",
       "        [1.0514e+06, 2.2145e+04, 5.0000e+00],\n",
       "        [1.0514e+06, 1.3393e+04, 5.0000e+00],\n",
       "        [1.0514e+06, 1.8300e+04, 5.0000e+00],\n",
       "        [1.0514e+06, 4.1222e+04, 5.0000e+00],\n",
       "        [1.0514e+06, 2.2145e+04, 5.0000e+00],\n",
       "        [1.0514e+06, 4.3438e+04, 4.0000e+00],\n",
       "        [1.0514e+06, 1.5691e+04, 4.0000e+00]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "\n",
    "        \"\"\" Architecture of the network \"\"\"\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size,16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,16),\n",
    "        )\n",
    "      \n",
    "\n",
    "    def forward(self,input1):\n",
    "        output1 = self.network(input1)\n",
    "        \n",
    "        \n",
    "        return output1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Siamese Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Triplet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(anchor_embed, positive_embed, negative_embed, margin=1.0):\n",
    "    distance_positive = torch.nn.functional.pairwise_distance(anchor_embed, positive_embed)\n",
    "    distance_negative = torch.nn.functional.pairwise_distance(anchor_embed, negative_embed)\n",
    "    \n",
    "    loss = torch.nn.functional.relu(distance_positive - distance_negative + margin)\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 10\n",
    "model = SiameseNetwork(3)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(epochs):\n",
    "    for batch in triplet_dataloader:\n",
    "        anchor = batch[:,0]\n",
    "        positive = batch[:,1]\n",
    "        negative = batch[:,2]\n",
    "\n",
    "        anchor_output = model(anchor)\n",
    "        positive_output = model(positive)\n",
    "        negative_output = model(negative)\n",
    "\n",
    "        #Triplet loss\n",
    "        loss = triplet_loss(anchor_output, positive_output, negative_output)\n",
    "\n",
    "        #Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test= df[['User_id', 'Business_id', 'Rating']].iloc[115:175]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to tensor\n",
    "test_tensor = torch.tensor(test.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=[]\n",
    "for input in test_tensor:\n",
    "    output = model(input)\n",
    "    embeddings.append(output.detach().numpy())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2277.915  , -3992.1597 ,  1805.6791 , -3170.4724 ,  1288.1118 ,\n",
       "       -1771.0773 , -1151.3721 ,  -167.62589,  2773.5547 ,  1685.4729 ,\n",
       "        3655.6655 , -1804.9977 ,  2099.8184 ,   -73.06734, -2357.4268 ,\n",
       "       -4431.4277 ], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
